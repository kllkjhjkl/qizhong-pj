{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef85ef9-fd22-4d81-ae46-8aa11bbf9e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.25.1\n",
      "✅ MMDetection安装成功!\n"
     ]
    }
   ],
   "source": [
    "import mmdet\n",
    "print(mmdet.__version__)\n",
    "\n",
    "# 测试导入\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "print(\"✅ MMDetection安装成功!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f725c8-488b-4515-91cf-992192e82fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始转换训练集...\n",
      "已处理 100 张图像...\n",
      "已处理 200 张图像...\n",
      "已处理 300 张图像...\n",
      "已处理 400 张图像...\n",
      "已处理 500 张图像...\n",
      "已处理 600 张图像...\n",
      "已处理 700 张图像...\n",
      "已处理 800 张图像...\n",
      "已处理 900 张图像...\n",
      "已处理 1000 张图像...\n",
      "已处理 1100 张图像...\n",
      "已处理 1200 张图像...\n",
      "已处理 1300 张图像...\n",
      "已处理 1400 张图像...\n",
      "转换完成: data/voc_coco_format/annotations2012/instances_train.json\n",
      "有效图像数量: 1464\n",
      "总标注数量: 3508\n",
      "\n",
      "开始转换验证集...\n",
      "已处理 100 张图像...\n",
      "已处理 200 张图像...\n",
      "已处理 300 张图像...\n",
      "已处理 400 张图像...\n",
      "已处理 500 张图像...\n",
      "已处理 600 张图像...\n",
      "已处理 700 张图像...\n",
      "已处理 800 张图像...\n",
      "已处理 900 张图像...\n",
      "已处理 1000 张图像...\n",
      "已处理 1100 张图像...\n",
      "已处理 1200 张图像...\n",
      "已处理 1300 张图像...\n",
      "已处理 1400 张图像...\n",
      "转换完成: data/voc_coco_format/annotations2012/instances_val.json\n",
      "有效图像数量: 1449\n",
      "总标注数量: 3426\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pycocotools import mask as maskUtils\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "class VOCToCOCOConverter:\n",
    "    def __init__(self, voc_root, output_dir):\n",
    "        self.voc_root = voc_root\n",
    "        self.output_dir = output_dir\n",
    "        self.categories = self._get_voc_categories()\n",
    "        \n",
    "    def _get_voc_categories(self):\n",
    "        \"\"\"VOC 2012的20个类别\"\"\"\n",
    "        categories = [\n",
    "            'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "            'bus', 'car', 'cat', 'chair', 'cow',\n",
    "            'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "            'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n",
    "        ]\n",
    "        return {cat: i+1 for i, cat in enumerate(categories)}\n",
    "    \n",
    "    def _parse_xml(self, xml_file):\n",
    "        \"\"\"解析VOC XML标注文件\"\"\"\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        objects_info = []\n",
    "        size = root.find('size')\n",
    "        img_width = int(size.find('width').text)\n",
    "        img_height = int(size.find('height').text)\n",
    "        \n",
    "        for obj in root.findall('object'):\n",
    "            name = obj.find('name').text\n",
    "            if name not in self.categories:\n",
    "                continue\n",
    "                \n",
    "            bbox_elem = obj.find('bndbox')\n",
    "            xmin = float(bbox_elem.find('xmin').text)\n",
    "            ymin = float(bbox_elem.find('ymin').text)\n",
    "            xmax = float(bbox_elem.find('xmax').text)\n",
    "            ymax = float(bbox_elem.find('ymax').text)\n",
    "            \n",
    "            # COCO格式: [x, y, width, height]\n",
    "            bbox = [xmin, ymin, xmax - xmin, ymax - ymin]\n",
    "            \n",
    "            objects_info.append({\n",
    "                'category_name': name,\n",
    "                'category_id': self.categories[name],\n",
    "                'bbox': bbox,\n",
    "                'iscrowd': 0\n",
    "            })\n",
    "            \n",
    "        return objects_info, img_width, img_height\n",
    "    \n",
    "    def _extract_instance_masks(self, seg_file, objects_info, img_width, img_height):\n",
    "        \"\"\"从VOC分割图像中提取每个实例的mask\"\"\"\n",
    "        if not os.path.exists(seg_file):\n",
    "            return []\n",
    "            \n",
    "        # 读取分割图像\n",
    "        seg_img = np.array(Image.open(seg_file))\n",
    "        \n",
    "        # 获取所有唯一的像素值（除了背景0和边界255）\n",
    "        unique_values = np.unique(seg_img)\n",
    "        unique_values = unique_values[(unique_values != 0) & (unique_values != 255)]\n",
    "        \n",
    "        annotations = []\n",
    "        \n",
    "        # 为每个检测到的对象匹配分割mask\n",
    "        for obj_info in objects_info:\n",
    "            # 在分割图像中寻找与边界框重叠最大的分割区域\n",
    "            x, y, w, h = obj_info['bbox']\n",
    "            x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "            \n",
    "            # 获取边界框区域内的分割值\n",
    "            bbox_region = seg_img[y:y+h, x:x+w]\n",
    "            bbox_unique = np.unique(bbox_region)\n",
    "            bbox_unique = bbox_unique[(bbox_unique != 0) & (bbox_unique != 255)]\n",
    "            \n",
    "            if len(bbox_unique) == 0:\n",
    "                # 如果没有找到分割区域，使用边界框创建矩形mask\n",
    "                mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "                mask[y:y+h, x:x+w] = 1\n",
    "            else:\n",
    "                # 选择在边界框内占比最大的分割值\n",
    "                best_value = None\n",
    "                max_overlap = 0\n",
    "                \n",
    "                for val in bbox_unique:\n",
    "                    if val in unique_values:\n",
    "                        val_mask = (seg_img == val).astype(np.uint8)\n",
    "                        overlap = np.sum(val_mask[y:y+h, x:x+w])\n",
    "                        if overlap > max_overlap:\n",
    "                            max_overlap = overlap\n",
    "                            best_value = val\n",
    "                \n",
    "                if best_value is not None:\n",
    "                    mask = (seg_img == best_value).astype(np.uint8)\n",
    "                    # 从unique_values中移除已使用的值，避免重复使用\n",
    "                    unique_values = unique_values[unique_values != best_value]\n",
    "                else:\n",
    "                    # 备选方案：使用边界框\n",
    "                    mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "                    mask[y:y+h, x:x+w] = 1\n",
    "            \n",
    "            # 计算面积\n",
    "            area = float(np.sum(mask))\n",
    "            \n",
    "            if area > 0:\n",
    "                # 转换为RLE格式\n",
    "                rle = maskUtils.encode(np.asfortranarray(mask))\n",
    "                rle['counts'] = rle['counts'].decode('utf-8')\n",
    "                \n",
    "                # 从mask重新计算更精确的边界框\n",
    "                coords = np.where(mask)\n",
    "                if len(coords[0]) > 0:\n",
    "                    y_min, y_max = coords[0].min(), coords[0].max()\n",
    "                    x_min, x_max = coords[1].min(), coords[1].max()\n",
    "                    precise_bbox = [float(x_min), float(y_min), \n",
    "                                  float(x_max - x_min + 1), float(y_max - y_min + 1)]\n",
    "                else:\n",
    "                    precise_bbox = obj_info['bbox']\n",
    "                \n",
    "                annotations.append({\n",
    "                    'category_id': obj_info['category_id'],\n",
    "                    'bbox': precise_bbox,\n",
    "                    'area': area,\n",
    "                    'segmentation': rle,\n",
    "                    'iscrowd': obj_info['iscrowd']\n",
    "                })\n",
    "        \n",
    "        return annotations\n",
    "    \n",
    "    def convert_split(self, split='train'):\n",
    "        \"\"\"转换指定的数据集分割\"\"\"\n",
    "        # 读取有分割标注的图像列表\n",
    "        seg_split_file = os.path.join(self.voc_root, 'ImageSets', 'Segmentation', f'{split}.txt')\n",
    "        \n",
    "        if not os.path.exists(seg_split_file):\n",
    "            print(f\"警告: 未找到分割数据集分割文件 {seg_split_file}\")\n",
    "            print(\"使用主数据集分割文件...\")\n",
    "            seg_split_file = os.path.join(self.voc_root, 'ImageSets', 'Main', f'{split}.txt')\n",
    "        \n",
    "        with open(seg_split_file, 'r') as f:\n",
    "            image_ids = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "        # 初始化COCO格式数据\n",
    "        coco_data = {\n",
    "            'info': {\n",
    "                'description': f'VOC Dataset with SegmentationObject converted to COCO format for {split}',\n",
    "                'version': '1.0',\n",
    "                'year': 2024,\n",
    "                'contributor': 'VOC to COCO Instance Segmentation Converter',\n",
    "                'date_created': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            },\n",
    "            'licenses': [],\n",
    "            'images': [],\n",
    "            'annotations': [],\n",
    "            'categories': []\n",
    "        }\n",
    "        \n",
    "        # 添加类别信息\n",
    "        for cat_name, cat_id in self.categories.items():\n",
    "            coco_data['categories'].append({\n",
    "                'id': cat_id,\n",
    "                'name': cat_name,\n",
    "                'supercategory': 'object'\n",
    "            })\n",
    "        \n",
    "        annotation_id = 1\n",
    "        valid_images = 0\n",
    "        \n",
    "        for img_id, image_id in enumerate(image_ids, 1):\n",
    "            # 检查所需文件是否存在\n",
    "            img_file = os.path.join(self.voc_root, 'JPEGImages', f'{image_id}.jpg')\n",
    "            xml_file = os.path.join(self.voc_root, 'Annotations', f'{image_id}.xml')\n",
    "            seg_file = os.path.join(self.voc_root, 'SegmentationObject', f'{image_id}.png')\n",
    "            \n",
    "            if not os.path.exists(img_file) or not os.path.exists(xml_file):\n",
    "                continue\n",
    "                \n",
    "            # 获取图像尺寸\n",
    "            with Image.open(img_file) as img:\n",
    "                img_width, img_height = img.size\n",
    "            \n",
    "            coco_data['images'].append({\n",
    "                'id': img_id,\n",
    "                'width': img_width,\n",
    "                'height': img_height,\n",
    "                'file_name': f'{image_id}.jpg'\n",
    "            })\n",
    "            \n",
    "            # 解析XML标注\n",
    "            objects_info, _, _ = self._parse_xml(xml_file)\n",
    "            \n",
    "            if len(objects_info) == 0:\n",
    "                continue\n",
    "            \n",
    "            # 提取实例mask\n",
    "            annotations = self._extract_instance_masks(seg_file, objects_info, img_width, img_height)\n",
    "            \n",
    "            for ann in annotations:\n",
    "                ann['id'] = annotation_id\n",
    "                ann['image_id'] = img_id\n",
    "                coco_data['annotations'].append(ann)\n",
    "                annotation_id += 1\n",
    "            \n",
    "            valid_images += 1\n",
    "            if valid_images % 100 == 0:\n",
    "                print(f\"已处理 {valid_images} 张图像...\")\n",
    "        \n",
    "        # 保存JSON文件\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        output_file = os.path.join(self.output_dir, f'instances_{split}.json')\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(coco_data, f, indent=2)\n",
    "            \n",
    "        print(f\"转换完成: {output_file}\")\n",
    "        print(f\"有效图像数量: {valid_images}\")\n",
    "        print(f\"总标注数量: {len(coco_data['annotations'])}\")\n",
    "        \n",
    "        return output_file\n",
    "\n",
    "def main():\n",
    "    # 配置路径\n",
    "    voc_root = 'data/VOCdevkit/VOC2012'  # 修改为你的VOC数据集路径\n",
    "    output_dir = 'data/voc_coco_format/annotations2012'\n",
    "    \n",
    "    converter = VOCToCOCOConverter(voc_root, output_dir)\n",
    "    \n",
    "    # 检查SegmentationObject文件夹是否存在\n",
    "    seg_obj_dir = os.path.join(voc_root, 'SegmentationObject')\n",
    "    if not os.path.exists(seg_obj_dir):\n",
    "        print(f\"错误: 未找到SegmentationObject文件夹: {seg_obj_dir}\")\n",
    "        print(\"请确保VOC数据集包含实例分割标注\")\n",
    "        return\n",
    "    \n",
    "    # 转换训练集和验证集\n",
    "    print(\"开始转换训练集...\")\n",
    "    converter.convert_split('train')\n",
    "    \n",
    "    print(\"\\n开始转换验证集...\")\n",
    "    converter.convert_split('val')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22cccb41-bb91-491b-a179-a0c1c6ea6d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SegmentationObject中有 2913 个分割文件\n",
      "开始转换训练集...\n",
      "开始处理 1464 张图像...\n",
      "已处理 100 张图像, 有效: 100\n",
      "已处理 200 张图像, 有效: 200\n",
      "已处理 300 张图像, 有效: 300\n",
      "已处理 400 张图像, 有效: 400\n",
      "已处理 500 张图像, 有效: 500\n",
      "已处理 600 张图像, 有效: 600\n",
      "已处理 700 张图像, 有效: 700\n",
      "已处理 800 张图像, 有效: 800\n",
      "已处理 900 张图像, 有效: 900\n",
      "已处理 1000 张图像, 有效: 1000\n",
      "已处理 1100 张图像, 有效: 1100\n",
      "已处理 1200 张图像, 有效: 1200\n",
      "已处理 1300 张图像, 有效: 1300\n",
      "已处理 1400 张图像, 有效: 1400\n",
      "\n",
      "转换完成: data/voc_coco_format/annotations2012/instances_train.json\n",
      "总处理图像: 1464\n",
      "有效图像数量: 1464\n",
      "跳过（无文件）: 0\n",
      "跳过（无对象）: 0\n",
      "总标注数量: 3567\n",
      "有效率: 100.0%\n",
      "\n",
      "开始转换验证集...\n",
      "开始处理 1449 张图像...\n",
      "已处理 100 张图像, 有效: 100\n",
      "已处理 200 张图像, 有效: 200\n",
      "已处理 300 张图像, 有效: 300\n",
      "已处理 400 张图像, 有效: 400\n",
      "已处理 500 张图像, 有效: 500\n",
      "已处理 600 张图像, 有效: 600\n",
      "已处理 700 张图像, 有效: 700\n",
      "已处理 800 张图像, 有效: 800\n",
      "已处理 900 张图像, 有效: 900\n",
      "已处理 1000 张图像, 有效: 1000\n",
      "已处理 1100 张图像, 有效: 1100\n",
      "已处理 1200 张图像, 有效: 1200\n",
      "已处理 1300 张图像, 有效: 1300\n",
      "已处理 1400 张图像, 有效: 1400\n",
      "\n",
      "转换完成: data/voc_coco_format/annotations2012/instances_val.json\n",
      "总处理图像: 1449\n",
      "有效图像数量: 1449\n",
      "跳过（无文件）: 0\n",
      "跳过（无对象）: 0\n",
      "总标注数量: 3489\n",
      "有效率: 100.0%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pycocotools import mask as maskUtils\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "class VOCToCOCOConverter:\n",
    "    def __init__(self, voc_root, output_dir):\n",
    "        self.voc_root = voc_root\n",
    "        self.output_dir = output_dir\n",
    "        self.categories = self._get_voc_categories()\n",
    "        \n",
    "    def _get_voc_categories(self):\n",
    "        \"\"\"VOC 2012的20个类别\"\"\"\n",
    "        categories = [\n",
    "            'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "            'bus', 'car', 'cat', 'chair', 'cow',\n",
    "            'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "            'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n",
    "        ]\n",
    "        return {cat: i+1 for i, cat in enumerate(categories)}\n",
    "    \n",
    "    def _parse_xml(self, xml_file):\n",
    "        \"\"\"解析VOC XML标注文件\"\"\"\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        objects_info = []\n",
    "        size = root.find('size')\n",
    "        img_width = int(size.find('width').text)\n",
    "        img_height = int(size.find('height').text)\n",
    "        \n",
    "        for obj in root.findall('object'):\n",
    "            name = obj.find('name').text\n",
    "            if name not in self.categories:\n",
    "                continue\n",
    "                \n",
    "            bbox_elem = obj.find('bndbox')\n",
    "            xmin = float(bbox_elem.find('xmin').text)\n",
    "            ymin = float(bbox_elem.find('ymin').text)\n",
    "            xmax = float(bbox_elem.find('xmax').text)\n",
    "            ymax = float(bbox_elem.find('ymax').text)\n",
    "            \n",
    "            # COCO格式: [x, y, width, height]\n",
    "            bbox = [xmin, ymin, xmax - xmin, ymax - ymin]\n",
    "            \n",
    "            objects_info.append({\n",
    "                'category_name': name,\n",
    "                'category_id': self.categories[name],\n",
    "                'bbox': bbox,\n",
    "                'iscrowd': 0\n",
    "            })\n",
    "            \n",
    "        return objects_info, img_width, img_height\n",
    "    \n",
    "    def _analyze_segmentation_image(self, seg_file):\n",
    "        \"\"\"分析分割图像中的像素值分布\"\"\"\n",
    "        if not os.path.exists(seg_file):\n",
    "            return None, None\n",
    "            \n",
    "        seg_img = np.array(Image.open(seg_file))\n",
    "        \n",
    "        # 获取所有非背景和非边界的像素值\n",
    "        unique_values = np.unique(seg_img)\n",
    "        # 过滤掉背景(0)和边界(255)\n",
    "        object_values = unique_values[(unique_values != 0) & (unique_values != 255)]\n",
    "        \n",
    "        return seg_img, object_values\n",
    "    \n",
    "    def _calculate_overlap(self, bbox, mask, threshold=0.3):\n",
    "        \"\"\"计算边界框与mask的重叠程度\"\"\"\n",
    "        x, y, w, h = [int(v) for v in bbox]\n",
    "        \n",
    "        # 确保边界框在图像范围内\n",
    "        img_h, img_w = mask.shape\n",
    "        x = max(0, min(x, img_w-1))\n",
    "        y = max(0, min(y, img_h-1))\n",
    "        w = min(w, img_w - x)\n",
    "        h = min(h, img_h - y)\n",
    "        \n",
    "        if w <= 0 or h <= 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # 计算边界框内的mask像素数\n",
    "        bbox_mask_pixels = np.sum(mask[y:y+h, x:x+w])\n",
    "        bbox_total_pixels = w * h\n",
    "        \n",
    "        # 计算重叠比例\n",
    "        overlap_ratio = bbox_mask_pixels / bbox_total_pixels if bbox_total_pixels > 0 else 0\n",
    "        \n",
    "        return overlap_ratio\n",
    "    \n",
    "    def _find_best_mask_for_bbox(self, bbox, seg_img, object_values, used_masks, min_overlap=0.1):\n",
    "        \"\"\"为边界框找到最佳匹配的mask\"\"\"\n",
    "        best_mask = None\n",
    "        best_overlap = 0\n",
    "        best_value = None\n",
    "        \n",
    "        for val in object_values:\n",
    "            if val in used_masks:\n",
    "                continue\n",
    "                \n",
    "            # 创建当前像素值的mask\n",
    "            current_mask = (seg_img == val).astype(np.uint8)\n",
    "            \n",
    "            # 计算重叠度\n",
    "            overlap = self._calculate_overlap(bbox, current_mask, min_overlap)\n",
    "            \n",
    "            if overlap > best_overlap and overlap >= min_overlap:\n",
    "                best_overlap = overlap\n",
    "                best_mask = current_mask\n",
    "                best_value = val\n",
    "        \n",
    "        return best_mask, best_value, best_overlap\n",
    "    \n",
    "    def _create_bbox_mask(self, bbox, img_width, img_height):\n",
    "        \"\"\"从边界框创建简单的矩形mask作为后备方案\"\"\"\n",
    "        x, y, w, h = [int(v) for v in bbox]\n",
    "        mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "        \n",
    "        # 确保坐标在有效范围内\n",
    "        x = max(0, min(x, img_width-1))\n",
    "        y = max(0, min(y, img_height-1))\n",
    "        w = min(w, img_width - x)\n",
    "        h = min(h, img_height - y)\n",
    "        \n",
    "        if w > 0 and h > 0:\n",
    "            mask[y:y+h, x:x+w] = 1\n",
    "            \n",
    "        return mask\n",
    "    \n",
    "    def _extract_instance_masks_improved(self, seg_file, objects_info, img_width, img_height):\n",
    "        \"\"\"改进的实例mask提取算法\"\"\"\n",
    "        if not os.path.exists(seg_file):\n",
    "            # 如果没有分割文件，使用边界框创建mask\n",
    "            print(f\"警告: 分割文件不存在 {os.path.basename(seg_file)}, 使用边界框mask\")\n",
    "            annotations = []\n",
    "            for obj_info in objects_info:\n",
    "                mask = self._create_bbox_mask(obj_info['bbox'], img_width, img_height)\n",
    "                area = float(np.sum(mask))\n",
    "                \n",
    "                if area > 0:\n",
    "                    rle = maskUtils.encode(np.asfortranarray(mask))\n",
    "                    rle['counts'] = rle['counts'].decode('utf-8')\n",
    "                    \n",
    "                    annotations.append({\n",
    "                        'category_id': obj_info['category_id'],\n",
    "                        'bbox': obj_info['bbox'],\n",
    "                        'area': area,\n",
    "                        'segmentation': rle,\n",
    "                        'iscrowd': obj_info['iscrowd']\n",
    "                    })\n",
    "            return annotations\n",
    "            \n",
    "        # 分析分割图像\n",
    "        seg_img, object_values = self._analyze_segmentation_image(seg_file)\n",
    "        \n",
    "        if object_values is None or len(object_values) == 0:\n",
    "            print(f\"警告: 分割图像中没有有效对象 {os.path.basename(seg_file)}\")\n",
    "            return []\n",
    "        \n",
    "        annotations = []\n",
    "        used_masks = set()\n",
    "        unmatched_objects = []\n",
    "        \n",
    "        # 第一轮：为每个边界框寻找最佳匹配的mask\n",
    "        for obj_info in objects_info:\n",
    "            best_mask, best_value, overlap = self._find_best_mask_for_bbox(\n",
    "                obj_info['bbox'], seg_img, object_values, used_masks, min_overlap=0.1\n",
    "            )\n",
    "            \n",
    "            if best_mask is not None and overlap > 0.1:\n",
    "                # 找到了合适的mask\n",
    "                area = float(np.sum(best_mask))\n",
    "                \n",
    "                if area > 0:\n",
    "                    # 标记该mask已被使用\n",
    "                    used_masks.add(best_value)\n",
    "                    \n",
    "                    # 从mask重新计算精确的边界框\n",
    "                    coords = np.where(best_mask)\n",
    "                    if len(coords[0]) > 0:\n",
    "                        y_min, y_max = coords[0].min(), coords[0].max()\n",
    "                        x_min, x_max = coords[1].min(), coords[1].max()\n",
    "                        precise_bbox = [float(x_min), float(y_min), \n",
    "                                      float(x_max - x_min + 1), float(y_max - y_min + 1)]\n",
    "                    else:\n",
    "                        precise_bbox = obj_info['bbox']\n",
    "                    \n",
    "                    # 转换为RLE格式\n",
    "                    rle = maskUtils.encode(np.asfortranarray(best_mask))\n",
    "                    rle['counts'] = rle['counts'].decode('utf-8')\n",
    "                    \n",
    "                    annotations.append({\n",
    "                        'category_id': obj_info['category_id'],\n",
    "                        'bbox': precise_bbox,\n",
    "                        'area': area,\n",
    "                        'segmentation': rle,\n",
    "                        'iscrowd': obj_info['iscrowd']\n",
    "                    })\n",
    "                else:\n",
    "                    unmatched_objects.append(obj_info)\n",
    "            else:\n",
    "                unmatched_objects.append(obj_info)\n",
    "        \n",
    "        # 第二轮：为未匹配的对象降低匹配阈值或使用边界框mask\n",
    "        for obj_info in unmatched_objects:\n",
    "            # 尝试更低的重叠阈值\n",
    "            best_mask, best_value, overlap = self._find_best_mask_for_bbox(\n",
    "                obj_info['bbox'], seg_img, object_values, used_masks, min_overlap=0.05\n",
    "            )\n",
    "            \n",
    "            if best_mask is not None and overlap > 0.05:\n",
    "                area = float(np.sum(best_mask))\n",
    "                if area > 0:\n",
    "                    used_masks.add(best_value)\n",
    "                    \n",
    "                    coords = np.where(best_mask)\n",
    "                    if len(coords[0]) > 0:\n",
    "                        y_min, y_max = coords[0].min(), coords[0].max()\n",
    "                        x_min, x_max = coords[1].min(), coords[1].max()\n",
    "                        precise_bbox = [float(x_min), float(y_min), \n",
    "                                      float(x_max - x_min + 1), float(y_max - y_min + 1)]\n",
    "                    else:\n",
    "                        precise_bbox = obj_info['bbox']\n",
    "                    \n",
    "                    rle = maskUtils.encode(np.asfortranarray(best_mask))\n",
    "                    rle['counts'] = rle['counts'].decode('utf-8')\n",
    "                    \n",
    "                    annotations.append({\n",
    "                        'category_id': obj_info['category_id'],\n",
    "                        'bbox': precise_bbox,\n",
    "                        'area': area,\n",
    "                        'segmentation': rle,\n",
    "                        'iscrowd': obj_info['iscrowd']\n",
    "                    })\n",
    "                    continue\n",
    "            \n",
    "            # 最后的备选方案：使用边界框mask\n",
    "            bbox_mask = self._create_bbox_mask(obj_info['bbox'], img_width, img_height)\n",
    "            area = float(np.sum(bbox_mask))\n",
    "            \n",
    "            if area > 0:\n",
    "                rle = maskUtils.encode(np.asfortranarray(bbox_mask))\n",
    "                rle['counts'] = rle['counts'].decode('utf-8')\n",
    "                \n",
    "                annotations.append({\n",
    "                    'category_id': obj_info['category_id'],\n",
    "                    'bbox': obj_info['bbox'],\n",
    "                    'area': area,\n",
    "                    'segmentation': rle,\n",
    "                    'iscrowd': obj_info['iscrowd']\n",
    "                })\n",
    "        \n",
    "        # 第三轮：处理未被任何边界框匹配的分割区域\n",
    "        unused_values = set(object_values) - used_masks\n",
    "        for val in unused_values:\n",
    "            mask = (seg_img == val).astype(np.uint8)\n",
    "            area = float(np.sum(mask))\n",
    "            \n",
    "            if area > 100:  # 只处理足够大的区域\n",
    "                # 尝试根据mask的位置推断类别\n",
    "                coords = np.where(mask)\n",
    "                if len(coords[0]) > 0:\n",
    "                    y_center = (coords[0].min() + coords[0].max()) / 2\n",
    "                    x_center = (coords[1].min() + coords[1].max()) / 2\n",
    "                    \n",
    "                    # 寻找最近的边界框来推断类别\n",
    "                    min_dist = float('inf')\n",
    "                    closest_category = 1  # 默认类别\n",
    "                    \n",
    "                    for obj_info in objects_info:\n",
    "                        bbox_x, bbox_y, bbox_w, bbox_h = obj_info['bbox']\n",
    "                        bbox_center_x = bbox_x + bbox_w / 2\n",
    "                        bbox_center_y = bbox_y + bbox_h / 2\n",
    "                        \n",
    "                        dist = ((x_center - bbox_center_x) ** 2 + (y_center - bbox_center_y) ** 2) ** 0.5\n",
    "                        if dist < min_dist:\n",
    "                            min_dist = dist\n",
    "                            closest_category = obj_info['category_id']\n",
    "                    \n",
    "                    # 计算精确边界框\n",
    "                    y_min, y_max = coords[0].min(), coords[0].max()\n",
    "                    x_min, x_max = coords[1].min(), coords[1].max()\n",
    "                    bbox = [float(x_min), float(y_min), \n",
    "                           float(x_max - x_min + 1), float(y_max - y_min + 1)]\n",
    "                    \n",
    "                    rle = maskUtils.encode(np.asfortranarray(mask))\n",
    "                    rle['counts'] = rle['counts'].decode('utf-8')\n",
    "                    \n",
    "                    annotations.append({\n",
    "                        'category_id': closest_category,\n",
    "                        'bbox': bbox,\n",
    "                        'area': area,\n",
    "                        'segmentation': rle,\n",
    "                        'iscrowd': 0\n",
    "                    })\n",
    "        \n",
    "        return annotations\n",
    "    \n",
    "    def convert_split(self, split='train'):\n",
    "        \"\"\"转换指定的数据集分割\"\"\"\n",
    "        # 读取有分割标注的图像列表\n",
    "        seg_split_file = os.path.join(self.voc_root, 'ImageSets', 'Segmentation', f'{split}.txt')\n",
    "        \n",
    "        if not os.path.exists(seg_split_file):\n",
    "            print(f\"警告: 未找到分割数据集分割文件 {seg_split_file}\")\n",
    "            print(\"使用主数据集分割文件...\")\n",
    "            seg_split_file = os.path.join(self.voc_root, 'ImageSets', 'Main', f'{split}.txt')\n",
    "        \n",
    "        with open(seg_split_file, 'r') as f:\n",
    "            image_ids = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "        # 初始化COCO格式数据\n",
    "        coco_data = {\n",
    "            'info': {\n",
    "                'description': f'VOC Dataset with SegmentationObject converted to COCO format for {split}',\n",
    "                'version': '2.0',\n",
    "                'year': 2024,\n",
    "                'contributor': 'Improved VOC to COCO Instance Segmentation Converter',\n",
    "                'date_created': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            },\n",
    "            'licenses': [],\n",
    "            'images': [],\n",
    "            'annotations': [],\n",
    "            'categories': []\n",
    "        }\n",
    "        \n",
    "        # 添加类别信息\n",
    "        for cat_name, cat_id in self.categories.items():\n",
    "            coco_data['categories'].append({\n",
    "                'id': cat_id,\n",
    "                'name': cat_name,\n",
    "                'supercategory': 'object'\n",
    "            })\n",
    "        \n",
    "        annotation_id = 1\n",
    "        valid_images = 0\n",
    "        total_processed = 0\n",
    "        skipped_no_objects = 0\n",
    "        skipped_no_files = 0\n",
    "        \n",
    "        print(f\"开始处理 {len(image_ids)} 张图像...\")\n",
    "        \n",
    "        for img_id, image_id in enumerate(image_ids, 1):\n",
    "            total_processed += 1\n",
    "            \n",
    "            # 检查所需文件是否存在\n",
    "            img_file = os.path.join(self.voc_root, 'JPEGImages', f'{image_id}.jpg')\n",
    "            xml_file = os.path.join(self.voc_root, 'Annotations', f'{image_id}.xml')\n",
    "            seg_file = os.path.join(self.voc_root, 'SegmentationObject', f'{image_id}.png')\n",
    "            \n",
    "            if not os.path.exists(img_file) or not os.path.exists(xml_file):\n",
    "                skipped_no_files += 1\n",
    "                continue\n",
    "                \n",
    "            # 获取图像尺寸\n",
    "            try:\n",
    "                with Image.open(img_file) as img:\n",
    "                    img_width, img_height = img.size\n",
    "            except Exception as e:\n",
    "                print(f\"无法读取图像 {image_id}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            coco_data['images'].append({\n",
    "                'id': img_id,\n",
    "                'width': img_width,\n",
    "                'height': img_height,\n",
    "                'file_name': f'{image_id}.jpg'\n",
    "            })\n",
    "            \n",
    "            # 解析XML标注\n",
    "            try:\n",
    "                objects_info, _, _ = self._parse_xml(xml_file)\n",
    "            except Exception as e:\n",
    "                print(f\"解析XML失败 {image_id}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            if len(objects_info) == 0:\n",
    "                skipped_no_objects += 1\n",
    "                continue\n",
    "            \n",
    "            # 提取实例mask（改进的算法）\n",
    "            annotations = self._extract_instance_masks_improved(seg_file, objects_info, img_width, img_height)\n",
    "            \n",
    "            if len(annotations) > 0:\n",
    "                for ann in annotations:\n",
    "                    ann['id'] = annotation_id\n",
    "                    ann['image_id'] = img_id\n",
    "                    coco_data['annotations'].append(ann)\n",
    "                    annotation_id += 1\n",
    "                \n",
    "                valid_images += 1\n",
    "            \n",
    "            if total_processed % 100 == 0:\n",
    "                print(f\"已处理 {total_processed} 张图像, 有效: {valid_images}\")\n",
    "        \n",
    "        # 保存JSON文件\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        output_file = os.path.join(self.output_dir, f'instances_{split}.json')\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(coco_data, f, indent=2)\n",
    "            \n",
    "        print(f\"\\n转换完成: {output_file}\")\n",
    "        print(f\"总处理图像: {total_processed}\")\n",
    "        print(f\"有效图像数量: {valid_images}\")\n",
    "        print(f\"跳过（无文件）: {skipped_no_files}\")\n",
    "        print(f\"跳过（无对象）: {skipped_no_objects}\")\n",
    "        print(f\"总标注数量: {len(coco_data['annotations'])}\")\n",
    "        print(f\"有效率: {valid_images/total_processed*100:.1f}%\")\n",
    "        \n",
    "        return output_file\n",
    "\n",
    "def main():\n",
    "    # 配置路径\n",
    "    voc_root = 'data/VOCdevkit/VOC2012'  # 修改为你的VOC数据集路径\n",
    "    output_dir = 'data/voc_coco_format/annotations2012'\n",
    "    \n",
    "    converter = VOCToCOCOConverter(voc_root, output_dir)\n",
    "    \n",
    "    # 检查必要文件夹\n",
    "    required_dirs = ['JPEGImages', 'Annotations', 'SegmentationObject', 'ImageSets']\n",
    "    for dir_name in required_dirs:\n",
    "        dir_path = os.path.join(voc_root, dir_name)\n",
    "        if not os.path.exists(dir_path):\n",
    "            print(f\"错误: 未找到必需文件夹: {dir_path}\")\n",
    "            return\n",
    "    \n",
    "    # 检查分割文件数量\n",
    "    seg_obj_dir = os.path.join(voc_root, 'SegmentationObject')\n",
    "    seg_files = [f for f in os.listdir(seg_obj_dir) if f.endswith('.png')]\n",
    "    print(f\"SegmentationObject中有 {len(seg_files)} 个分割文件\")\n",
    "    \n",
    "    # 转换训练集和验证集\n",
    "    print(\"开始转换训练集...\")\n",
    "    converter.convert_split('train')\n",
    "    \n",
    "    print(\"\\n开始转换验证集...\")\n",
    "    converter.convert_split('val')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14cdc345-9c49-4a51-8f37-8aa5b14553ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VOC数据集转换为COCO格式 (训练:验证 = 4:1)\n",
      "============================================================\n",
      "开始数据转换...\n",
      "使用分割数据集的trainval.txt\n",
      "找到 2913 个有分割标注的图像\n",
      "数据集划分:\n",
      "  训练集: 2330 个图像 (80.0%)\n",
      "  验证集: 583 个图像 (20.0%)\n",
      "\n",
      "转换训练集 (2330 个图像)...\n",
      "已处理 100 张图像...\n",
      "已处理 200 张图像...\n",
      "已处理 300 张图像...\n",
      "已处理 400 张图像...\n",
      "已处理 500 张图像...\n",
      "已处理 600 张图像...\n",
      "已处理 700 张图像...\n",
      "已处理 800 张图像...\n",
      "已处理 900 张图像...\n",
      "已处理 1000 张图像...\n",
      "已处理 1100 张图像...\n",
      "已处理 1200 张图像...\n",
      "已处理 1300 张图像...\n",
      "已处理 1400 张图像...\n",
      "已处理 1500 张图像...\n",
      "已处理 1600 张图像...\n",
      "已处理 1700 张图像...\n",
      "已处理 1800 张图像...\n",
      "已处理 1900 张图像...\n",
      "已处理 2000 张图像...\n",
      "已处理 2100 张图像...\n",
      "已处理 2200 张图像...\n",
      "已处理 2300 张图像...\n",
      "转换完成: data/voc_coco_format2/annotations/instances_train.json\n",
      "有效图像数量: 2330\n",
      "总标注数量: 5558\n",
      "\n",
      "转换验证集 (583 个图像)...\n",
      "已处理 100 张图像...\n",
      "已处理 200 张图像...\n",
      "已处理 300 张图像...\n",
      "已处理 400 张图像...\n",
      "已处理 500 张图像...\n",
      "转换完成: data/voc_coco_format2/annotations/instances_val.json\n",
      "有效图像数量: 583\n",
      "总标注数量: 1376\n",
      "\n",
      "============================================================\n",
      "✓ 数据转换完成!\n",
      "✓ 训练集标注: data/voc_coco_format2/annotations/instances_train.json\n",
      "✓ 验证集标注: data/voc_coco_format2/annotations/instances_val.json\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pycocotools import mask as maskUtils\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "class VOCToCOCOConverter:\n",
    "    def __init__(self, voc_root, output_dir):\n",
    "        self.voc_root = voc_root\n",
    "        self.output_dir = output_dir\n",
    "        self.categories = self._get_voc_categories()\n",
    "        \n",
    "    def _get_voc_categories(self):\n",
    "        \"\"\"VOC 2012的20个类别\"\"\"\n",
    "        categories = [\n",
    "            'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "            'bus', 'car', 'cat', 'chair', 'cow',\n",
    "            'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "            'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n",
    "        ]\n",
    "        return {cat: i+1 for i, cat in enumerate(categories)}\n",
    "    \n",
    "    def _parse_xml(self, xml_file):\n",
    "        \"\"\"解析VOC XML标注文件\"\"\"\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        objects_info = []\n",
    "        size = root.find('size')\n",
    "        img_width = int(size.find('width').text)\n",
    "        img_height = int(size.find('height').text)\n",
    "        \n",
    "        for obj in root.findall('object'):\n",
    "            name = obj.find('name').text\n",
    "            if name not in self.categories:\n",
    "                continue\n",
    "                \n",
    "            bbox_elem = obj.find('bndbox')\n",
    "            xmin = float(bbox_elem.find('xmin').text)\n",
    "            ymin = float(bbox_elem.find('ymin').text)\n",
    "            xmax = float(bbox_elem.find('xmax').text)\n",
    "            ymax = float(bbox_elem.find('ymax').text)\n",
    "            \n",
    "            # COCO格式: [x, y, width, height]\n",
    "            bbox = [xmin, ymin, xmax - xmin, ymax - ymin]\n",
    "            \n",
    "            objects_info.append({\n",
    "                'category_name': name,\n",
    "                'category_id': self.categories[name],\n",
    "                'bbox': bbox,\n",
    "                'iscrowd': 0\n",
    "            })\n",
    "            \n",
    "        return objects_info, img_width, img_height\n",
    "    \n",
    "    def _extract_instance_masks(self, seg_file, objects_info, img_width, img_height):\n",
    "        \"\"\"从VOC分割图像中提取每个实例的mask\"\"\"\n",
    "        if not os.path.exists(seg_file):\n",
    "            return []\n",
    "            \n",
    "        # 读取分割图像\n",
    "        seg_img = np.array(Image.open(seg_file))\n",
    "        \n",
    "        # 获取所有唯一的像素值（除了背景0和边界255）\n",
    "        unique_values = np.unique(seg_img)\n",
    "        unique_values = unique_values[(unique_values != 0) & (unique_values != 255)]\n",
    "        \n",
    "        annotations = []\n",
    "        \n",
    "        # 为每个检测到的对象匹配分割mask\n",
    "        for obj_info in objects_info:\n",
    "            # 在分割图像中寻找与边界框重叠最大的分割区域\n",
    "            x, y, w, h = obj_info['bbox']\n",
    "            x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "            \n",
    "            # 获取边界框区域内的分割值\n",
    "            bbox_region = seg_img[y:y+h, x:x+w]\n",
    "            bbox_unique = np.unique(bbox_region)\n",
    "            bbox_unique = bbox_unique[(bbox_unique != 0) & (bbox_unique != 255)]\n",
    "            \n",
    "            if len(bbox_unique) == 0:\n",
    "                # 如果没有找到分割区域，使用边界框创建矩形mask\n",
    "                mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "                mask[y:y+h, x:x+w] = 1\n",
    "            else:\n",
    "                # 选择在边界框内占比最大的分割值\n",
    "                best_value = None\n",
    "                max_overlap = 0\n",
    "                \n",
    "                for val in bbox_unique:\n",
    "                    if val in unique_values:\n",
    "                        val_mask = (seg_img == val).astype(np.uint8)\n",
    "                        overlap = np.sum(val_mask[y:y+h, x:x+w])\n",
    "                        if overlap > max_overlap:\n",
    "                            max_overlap = overlap\n",
    "                            best_value = val\n",
    "                \n",
    "                if best_value is not None:\n",
    "                    mask = (seg_img == best_value).astype(np.uint8)\n",
    "                    # 从unique_values中移除已使用的值，避免重复使用\n",
    "                    unique_values = unique_values[unique_values != best_value]\n",
    "                else:\n",
    "                    # 备选方案：使用边界框\n",
    "                    mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "                    mask[y:y+h, x:x+w] = 1\n",
    "            \n",
    "            # 计算面积\n",
    "            area = float(np.sum(mask))\n",
    "            \n",
    "            if area > 0:\n",
    "                # 转换为RLE格式\n",
    "                rle = maskUtils.encode(np.asfortranarray(mask))\n",
    "                rle['counts'] = rle['counts'].decode('utf-8')\n",
    "                \n",
    "                # 从mask重新计算更精确的边界框\n",
    "                coords = np.where(mask)\n",
    "                if len(coords[0]) > 0:\n",
    "                    y_min, y_max = coords[0].min(), coords[0].max()\n",
    "                    x_min, x_max = coords[1].min(), coords[1].max()\n",
    "                    precise_bbox = [float(x_min), float(y_min), \n",
    "                                  float(x_max - x_min + 1), float(y_max - y_min + 1)]\n",
    "                else:\n",
    "                    precise_bbox = obj_info['bbox']\n",
    "                \n",
    "                annotations.append({\n",
    "                    'category_id': obj_info['category_id'],\n",
    "                    'bbox': precise_bbox,\n",
    "                    'area': area,\n",
    "                    'segmentation': rle,\n",
    "                    'iscrowd': obj_info['iscrowd']\n",
    "                })\n",
    "        \n",
    "        return annotations\n",
    "    \n",
    "    def get_all_segmentation_images(self):\n",
    "        \"\"\"获取所有有分割标注的图像ID\"\"\"\n",
    "        # 优先使用分割数据集的trainval文件\n",
    "        seg_trainval_file = os.path.join(self.voc_root, 'ImageSets', 'Segmentation', 'trainval.txt')\n",
    "        \n",
    "        if os.path.exists(seg_trainval_file):\n",
    "            print(\"使用分割数据集的trainval.txt\")\n",
    "            with open(seg_trainval_file, 'r') as f:\n",
    "                all_image_ids = [line.strip() for line in f.readlines()]\n",
    "        else:\n",
    "            # 如果没有trainval.txt，尝试合并train.txt和val.txt\n",
    "            train_file = os.path.join(self.voc_root, 'ImageSets', 'Segmentation', 'train.txt')\n",
    "            val_file = os.path.join(self.voc_root, 'ImageSets', 'Segmentation', 'val.txt')\n",
    "            \n",
    "            all_image_ids = []\n",
    "            if os.path.exists(train_file):\n",
    "                with open(train_file, 'r') as f:\n",
    "                    all_image_ids.extend([line.strip() for line in f.readlines()])\n",
    "            \n",
    "            if os.path.exists(val_file):\n",
    "                with open(val_file, 'r') as f:\n",
    "                    all_image_ids.extend([line.strip() for line in f.readlines()])\n",
    "            \n",
    "            if not all_image_ids:\n",
    "                # 最后的备选方案：从SegmentationObject目录直接获取\n",
    "                seg_obj_dir = os.path.join(self.voc_root, 'SegmentationObject')\n",
    "                if os.path.exists(seg_obj_dir):\n",
    "                    print(\"从SegmentationObject目录获取图像列表\")\n",
    "                    seg_files = [f for f in os.listdir(seg_obj_dir) if f.endswith('.png')]\n",
    "                    all_image_ids = [f[:-4] for f in seg_files]  # 移除.png后缀\n",
    "                else:\n",
    "                    raise ValueError(\"无法找到分割数据集的图像列表\")\n",
    "        \n",
    "        # 去重并排序\n",
    "        all_image_ids = sorted(list(set(all_image_ids)))\n",
    "        print(f\"找到 {len(all_image_ids)} 个有分割标注的图像\")\n",
    "        \n",
    "        return all_image_ids\n",
    "    \n",
    "    def split_train_val(self, all_image_ids, train_ratio=0.8):\n",
    "        \"\"\"按比例划分训练集和验证集\"\"\"\n",
    "        # 设置随机种子保证结果可复现\n",
    "        random.seed(42)\n",
    "        \n",
    "        # 打乱图像ID列表\n",
    "        shuffled_ids = all_image_ids.copy()\n",
    "        random.shuffle(shuffled_ids)\n",
    "        \n",
    "        # 计算分割点\n",
    "        total_count = len(shuffled_ids)\n",
    "        train_count = int(total_count * train_ratio)\n",
    "        \n",
    "        train_ids = shuffled_ids[:train_count]\n",
    "        val_ids = shuffled_ids[train_count:]\n",
    "        \n",
    "        print(f\"数据集划分:\")\n",
    "        print(f\"  训练集: {len(train_ids)} 个图像 ({len(train_ids)/total_count*100:.1f}%)\")\n",
    "        print(f\"  验证集: {len(val_ids)} 个图像 ({len(val_ids)/total_count*100:.1f}%)\")\n",
    "        \n",
    "        return train_ids, val_ids\n",
    "\n",
    "    def convert_split(self, image_ids, split='train'):\n",
    "        \"\"\"转换指定的数据集分割\"\"\"\n",
    "        \n",
    "        # 初始化COCO格式数据\n",
    "        coco_data = {\n",
    "            'info': {\n",
    "                'description': f'VOC Dataset with SegmentationObject converted to COCO format for {split}',\n",
    "                'version': '1.0',\n",
    "                'year': 2024,\n",
    "                'contributor': 'VOC to COCO Instance Segmentation Converter',\n",
    "                'date_created': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            },\n",
    "            'licenses': [],\n",
    "            'images': [],\n",
    "            'annotations': [],\n",
    "            'categories': []\n",
    "        }\n",
    "        \n",
    "        # 添加类别信息\n",
    "        for cat_name, cat_id in self.categories.items():\n",
    "            coco_data['categories'].append({\n",
    "                'id': cat_id,\n",
    "                'name': cat_name,\n",
    "                'supercategory': 'object'\n",
    "            })\n",
    "        \n",
    "        annotation_id = 1\n",
    "        valid_images = 0\n",
    "        \n",
    "        for img_id, image_id in enumerate(image_ids, 1):\n",
    "            # 检查所需文件是否存在\n",
    "            img_file = os.path.join(self.voc_root, 'JPEGImages', f'{image_id}.jpg')\n",
    "            xml_file = os.path.join(self.voc_root, 'Annotations', f'{image_id}.xml')\n",
    "            seg_file = os.path.join(self.voc_root, 'SegmentationObject', f'{image_id}.png')\n",
    "            \n",
    "            if not os.path.exists(img_file) or not os.path.exists(xml_file):\n",
    "                continue\n",
    "                \n",
    "            # 获取图像尺寸\n",
    "            with Image.open(img_file) as img:\n",
    "                img_width, img_height = img.size\n",
    "            \n",
    "            coco_data['images'].append({\n",
    "                'id': img_id,\n",
    "                'width': img_width,\n",
    "                'height': img_height,\n",
    "                'file_name': f'{image_id}.jpg'\n",
    "            })\n",
    "            \n",
    "            # 解析XML标注\n",
    "            objects_info, _, _ = self._parse_xml(xml_file)\n",
    "            \n",
    "            if len(objects_info) == 0:\n",
    "                continue\n",
    "            \n",
    "            # 提取实例mask\n",
    "            annotations = self._extract_instance_masks(seg_file, objects_info, img_width, img_height)\n",
    "            \n",
    "            for ann in annotations:\n",
    "                ann['id'] = annotation_id\n",
    "                ann['image_id'] = img_id\n",
    "                coco_data['annotations'].append(ann)\n",
    "                annotation_id += 1\n",
    "            \n",
    "            valid_images += 1\n",
    "            if valid_images % 100 == 0:\n",
    "                print(f\"已处理 {valid_images} 张图像...\")\n",
    "        \n",
    "        # 保存JSON文件\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        output_file = os.path.join(self.output_dir, f'instances_{split}.json')\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(coco_data, f, indent=2)\n",
    "            \n",
    "        print(f\"转换完成: {output_file}\")\n",
    "        print(f\"有效图像数量: {valid_images}\")\n",
    "        print(f\"总标注数量: {len(coco_data['annotations'])}\")\n",
    "        \n",
    "        return output_file\n",
    "\n",
    "    def convert_all_data(self, train_ratio=0.8):\n",
    "        \"\"\"转换所有数据并按比例划分训练集和验证集\"\"\"\n",
    "        print(\"开始数据转换...\")\n",
    "        \n",
    "        # 1. 获取所有有分割标注的图像\n",
    "        all_image_ids = self.get_all_segmentation_images()\n",
    "        \n",
    "        # 2. 按比例划分训练集和验证集\n",
    "        train_ids, val_ids = self.split_train_val(all_image_ids, train_ratio)\n",
    "        \n",
    "        # 3. 转换训练集\n",
    "        print(f\"\\n转换训练集 ({len(train_ids)} 个图像)...\")\n",
    "        train_file = self.convert_split(train_ids, 'train')\n",
    "        \n",
    "        # 4. 转换验证集\n",
    "        print(f\"\\n转换验证集 ({len(val_ids)} 个图像)...\")\n",
    "        val_file = self.convert_split(val_ids, 'val')\n",
    "        \n",
    "        return train_file, val_file\n",
    "\n",
    "def main():\n",
    "    # 配置路径\n",
    "    voc_root = 'data/VOCdevkit/VOC2012'  # 修改为你的VOC数据集路径\n",
    "    output_dir = 'data/voc_coco_format2/annotations'\n",
    "    \n",
    "    converter = VOCToCOCOConverter(voc_root, output_dir)\n",
    "    \n",
    "    # 检查SegmentationObject文件夹是否存在\n",
    "    seg_obj_dir = os.path.join(voc_root, 'SegmentationObject')\n",
    "    if not os.path.exists(seg_obj_dir):\n",
    "        print(f\"错误: 未找到SegmentationObject文件夹: {seg_obj_dir}\")\n",
    "        print(\"请确保VOC数据集包含实例分割标注\")\n",
    "        return\n",
    "    \n",
    "    # 使用4:1比例划分训练集和验证集\n",
    "    print(\"=\" * 60)\n",
    "    print(\"VOC数据集转换为COCO格式 (训练:验证 = 4:1)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        train_file, val_file = converter.convert_all_data(train_ratio=0.8)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"✓ 数据转换完成!\")\n",
    "        print(f\"✓ 训练集标注: {train_file}\")\n",
    "        print(f\"✓ 验证集标注: {val_file}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 转换失败: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af3053-6a44-47b0-9555-7fa85c2dba2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
